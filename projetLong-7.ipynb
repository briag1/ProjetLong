{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Seed for Repoducibility"
      ],
      "metadata": {
        "id": "aXTMKqdKAerO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import string\n",
        "import random\n",
        "def get_reproducible_seeds(name=\"ProjectLong\",nb_seeds=100):\n",
        "    # Calculate SHA-256 hash\n",
        "    sha256_hash = hashlib.sha256(name.encode()).hexdigest()\n",
        "    # Define character sets\n",
        "    digits = string.digits\n",
        "    # Use the hash to seed the random number generator\n",
        "    hash_as_int = int(sha256_hash, 16)\n",
        "    random.seed(hash_as_int)\n",
        "    # Generate a random list of seed of desired length\n",
        "    reproducibility_seeds = [random.randint(0,10000) for _ in range(nb_seeds)]\n",
        "\n",
        "    return reproducibility_seeds"
      ],
      "metadata": {
        "id": "Bju3dTbAAzmf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reproducibility_seed=get_reproducible_seeds()[0]"
      ],
      "metadata": {
        "id": "5tgzpsNzA5Sy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e_4knsUngrP"
      },
      "source": [
        "# Small Dataset (15 days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMRrM7OBmrQU",
        "outputId": "63584f30-d7ee-43e4-9438-64c3a8558705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-12 13:26:44--  http://sguangwang.com/dataset/telecom.zip\n",
            "Resolving sguangwang.com (sguangwang.com)... 182.50.151.114\n",
            "Connecting to sguangwang.com (sguangwang.com)|182.50.151.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53432897 (51M) [application/x-zip-compressed]\n",
            "Saving to: ‘telecom.zip’\n",
            "\n",
            "telecom.zip         100%[===================>]  50.96M  12.2MB/s    in 5.0s    \n",
            "\n",
            "2024-02-12 13:26:50 (10.3 MB/s) - ‘telecom.zip’ saved [53432897/53432897]\n",
            "\n",
            "Archive:  /content/telecom.zip\n",
            "  inflating: dataset-telecom/data_6.1~6.30_.xlsx  \n"
          ]
        }
      ],
      "source": [
        "!wget http://sguangwang.com/dataset/telecom.zip\n",
        "!unzip /content/telecom.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_excel(\"/content/dataset-telecom/data_6.1~6.30_.xlsx\")\n",
        "df.to_pickle(\"telecom_data.pkl\")"
      ],
      "metadata": {
        "id": "0gKIATWJepJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "_rLK4ueroFgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepocessing"
      ],
      "metadata": {
        "id": "7dxTDF02oVl2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9noRaylvcRR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df= pd.read_pickle(\"telecom_data.pkl\")\n",
        "df=df.sort_values('start time')\n",
        "def get_x(value):\n",
        "    if isinstance(value, str):\n",
        "        return float(value.split(\"/\")[0])\n",
        "    elif isinstance(value, float):\n",
        "        return value\n",
        "def get_y(value):\n",
        "    if isinstance(value, str):\n",
        "        return float(value.split(\"/\")[1])\n",
        "    elif isinstance(value, float):\n",
        "        return value\n",
        "\n",
        "df['x'] = df['location(latitude/lontitude)'].apply(get_x)\n",
        "df['y'] = df['location(latitude/lontitude)'].apply(get_y)\n",
        "df['x_normalised']=(df['x']-df['x'].mean())/(df['x'].std())\n",
        "df['y_normalised']=(df['y']-df['y'].mean())/df['y'].std()\n",
        "df['pos']= list(zip(df['x'],df['y']))\n",
        "\n",
        "import math\n",
        "pos=df['pos'].unique()\n",
        "vocab=dict(zip(pos,range(len(pos))))\n",
        "vocab[(float('nan'),float('nan'))]=len(vocab)\n",
        "def tokenize_pos(pos):\n",
        "  if math.isnan(pos[0]) and math.isnan(pos[1]):\n",
        "    return len(vocab)\n",
        "  else:\n",
        "    return vocab[pos]\n",
        "df['pos_id'] = df['pos'].apply(tokenize_pos)\n",
        "\n",
        "#create encoded time series\n",
        "min_year = df[\"start time\"].dt.year.min()\n",
        "max_year = df[\"start time\"].dt.year.max()\n",
        "df['year_normalised'] = (df[\"start time\"].dt.year - min_year) / (max_year - min_year)\n",
        "\n",
        "df['month_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.month / 12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.month / 12)\n",
        "\n",
        "df['day_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.day / 31)\n",
        "df['day_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.day / 31)\n",
        "\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.hour / 24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.hour / 24)\n",
        "\n",
        "df['minute_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.minute / 60)\n",
        "df['minute_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.minute / 60)\n",
        "\n",
        "df['second_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.second / 60)\n",
        "df['second_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.second / 60)\n",
        "\n",
        "df['time_to_end']=df['end time']-df['start time']\n",
        "df['time_to_end']=df['time_to_end'].dt.total_seconds()\n",
        "\n",
        "df=df.drop(['month', 'date', 'end time', 'location(latitude/lontitude)', 'x', 'y','pos'], axis=1)\n",
        "df_user_group = df.groupby('user id')\n",
        "list_users=[]\n",
        "for user, df_user in df_user_group:\n",
        "  if len(df_user)>=2:\n",
        "    df_user[\"time_to_next\"] =  df_user[\"start time\"].diff(-1).dt.total_seconds()\n",
        "    dict_user=df_user.to_dict('list')\n",
        "    dict_user[\"time_to_next\"][-1]=-1.\n",
        "    dict_user[\"pos_id\"]=torch.tensor(dict_user[\"pos_id\"]+[len(vocab)+1])\n",
        "\n",
        "    dict_user[\"pos_id_target\"]=dict_user[\"pos_id\"][1:]\n",
        "    dict_user[\"pos_id\"]=dict_user[\"pos_id\"][:-1]\n",
        "    dict_user[\"input\"]=torch.tensor([dict_user[\"x_normalised\"],dict_user[\"y_normalised\"],dict_user['month_sin'], dict_user['month_cos'], dict_user['day_sin'], dict_user['day_cos'], dict_user['hour_sin'], dict_user['hour_cos'], dict_user['minute_sin'], dict_user['minute_cos'], dict_user['second_sin'], dict_user['second_cos']]).T\n",
        "    #print(dict_user[\"input\"].shape,dict_user[\"input\"].T.shape)\n",
        "    dict_user[\"time_target\"]=torch.tensor([dict_user[\"time_to_end\"],dict_user[\"time_to_next\"]]).T\n",
        "    j=1\n",
        "    i=0\n",
        "    while i < dict_user[\"input\"].size(0) and torch.isnan(dict_user[\"input\"][i,j]):\n",
        "      i+=1\n",
        "    if i < dict_user[\"input\"].size(0):\n",
        "      dict_user[\"input\"][:i,0]=dict_user[\"input\"][i,0]\n",
        "      dict_user[\"input\"][:i,1]=dict_user[\"input\"][i,1]\n",
        "      nan_positions = torch.isnan(dict_user[\"input\"])\n",
        "      # Step 2: Replace NaN values with the values from the preceding row of the same column\n",
        "      for i in range(i+1, dict_user[\"input\"].size(0)):\n",
        "        dict_user[\"input\"][i, nan_positions[i]] = dict_user[\"input\"][i - 1, nan_positions[i]]\n",
        "\n",
        "      for e in ['x_normalised', 'y_normalised','year_normalised', 'month_sin', 'month_cos', 'day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', 'second_sin', 'second_cos', 'time_to_end', 'time_to_next','start time', 'user id']:\n",
        "        dict_user.pop(e)\n",
        "      list_users.append(dict_user)\n",
        "time_targets=torch.cat([dict_user[\"time_target\"] for dict_user in list_users],dim=0)\n",
        "time_targets_mean=time_targets.mean(dim=0)\n",
        "time_targets_std=time_targets.std(dim=0)\n",
        "\n",
        "for i in range(len(list_users)):\n",
        "  list_users[i][\"time_target\"]=(list_users[i][\"time_target\"]-time_targets_mean)/time_targets_std\n",
        "torch.save(list_users,\"list_users\")\n",
        "torch.save(vocab,'vocab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "list_users=torch.load(\"list_users\")\n",
        "vocab= torch.load('vocab')"
      ],
      "metadata": {
        "id": "w4avFZ_xQZDp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "ri0aBbZ6ofcq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KIQ6wSr07WH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class VariableLengthDataset(Dataset):\n",
        "    def __init__(self, time_series, transform=None):\n",
        "        self.times_series=time_series\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.times_series)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_dict=self.times_series[idx]\n",
        "\n",
        "        return  user_dict['input'],user_dict['pos_id_target'], user_dict['time_target']\n",
        "\n",
        "dataset=VariableLengthDataset(list_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKrblvqPjYgr",
        "outputId": "d6139dca-90b1-4e86-c907-a1b9e4578deb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([14, 12])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.__getitem__(0)[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT--gp5X48-e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "def collate_fn_padd(batch):\n",
        "    '''\n",
        "    Padds batch of variable length\n",
        "\n",
        "    note: it converts things ToTensor manually here since the ToTensor transform\n",
        "    assume it takes in images rather than arbitrary tensors.\n",
        "    '''\n",
        "    ## get sequence lengths\n",
        "    inputs,pos_ids,time_targets=zip(*batch)\n",
        "    lengths = torch.tensor([ input.shape[0] for input in inputs ])\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs,batch_first=True,padding_value=0)\n",
        "    time_targets = torch.nn.utils.rnn.pad_sequence(time_targets,batch_first=True,padding_value=-1)\n",
        "    pos_ids = torch.nn.utils.rnn.pad_sequence(pos_ids,batch_first=True,padding_value=len(vocab))\n",
        "\n",
        "    ## compute mask\n",
        "    mask_time_targets = (time_targets != -1)\n",
        "    return inputs, time_targets, pos_ids, lengths, mask_time_targets\n",
        "dataloader=DataLoader(dataset,batch_size=64,collate_fn=collate_fn_padd,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00GSf1hmRX8G"
      },
      "outputs": [],
      "source": [
        "next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classic Training\n"
      ],
      "metadata": {
        "id": "lhKUvvMSgNIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAtLmhUa5Bmd",
        "outputId": "11db7182-8145-4d12-93fe-e4bfbdca5fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0 loss: 18.840499846140542\n",
            "epoch: 1 loss: 18.608480728997126\n",
            "epoch: 2 loss: 18.47722815407647\n",
            "epoch: 3 loss: 19.080203787485758\n",
            "epoch: 4 loss: 18.70116665098402\n",
            "epoch: 5 loss: 18.936610984802247\n",
            "epoch: 6 loss: 18.500861348046197\n",
            "epoch: 7 loss: 19.131100294325087\n",
            "epoch: 8 loss: 18.758988920847575\n",
            "epoch: 9 loss: 18.878969764709474\n",
            "epoch: 10 loss: 18.871430248684355\n",
            "epoch: 11 loss: 18.270792081620957\n",
            "epoch: 12 loss: 18.589879290262857\n",
            "epoch: 13 loss: 18.64937384923299\n",
            "epoch: 14 loss: 18.908659415774874\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding, LSTM\n",
        "import torch.nn.functional as F\n",
        "from torch import autocast\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "epochs=17\n",
        "encoder=LSTM(input_size=12, hidden_size=len(vocab)+4,batch_first=True,num_layers=2).cuda()\n",
        "optimizer_encoder = optim.Adam(encoder.parameters())\n",
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "train_losses=[]\n",
        "for epoch in range(epochs):\n",
        "  epoch_losses=[]\n",
        "  for inputs, time_targets, pos_ids, lengths, mask_time_targets in dataloader:\n",
        "    optimizer_encoder.zero_grad()\n",
        "    inputs=inputs.float().cuda()\n",
        "    time_targets = time_targets.cuda()\n",
        "    pos_ids = pos_ids.cuda()\n",
        "    mask_time_targets = mask_time_targets.cuda()\n",
        "    packed_batch=torch.nn.utils.rnn.pack_padded_sequence(inputs, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    with autocast(device_type=\"cuda\"):\n",
        "      packed_output,(ht, ct)=encoder(packed_batch)\n",
        "      output, input_sizes = pad_packed_sequence(packed_output,batch_first=True)\n",
        "      loss_classification=criterion_classification(output[:,:,:len(vocab)+2].transpose(1,2),pos_ids)\n",
        "      loss_regression=criterion_regression(F.relu(output[:,:,len(vocab)+2:]),time_targets)\n",
        "      loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "      loss=loss_classification+1e-7*loss_regression\n",
        "    loss.backward()\n",
        "    optimizer_encoder.step()\n",
        "    epoch_losses.append(loss.cpu().item())\n",
        "  loss_epoch=np.mean(epoch_losses)\n",
        "  print(\"epoch: \"+str(epoch)+\" loss: \"+str(loss_epoch))\n",
        "  train_losses.append(loss_epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequencing Classification and regression"
      ],
      "metadata": {
        "id": "X2mBLgVmgasE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding, LSTM\n",
        "import torch.nn.functional as F\n",
        "from torch import autocast\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "epochs_classifcation_only=10\n",
        "epochs_complete_problem =10\n",
        "lr=0.001\n",
        "epochs=epochs_complete_problem+ epochs_classifcation_only\n",
        "encoder=LSTM(input_size=12, hidden_size=len(vocab)+4,batch_first=True,num_layers=2).cuda()\n",
        "optimizer_encoder = optim.Adam(encoder.parameters(),lr=lr)\n",
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "train_losses=[]\n",
        "for epoch in range(epochs):\n",
        "  epoch_losses=[]\n",
        "  for inputs, time_targets, pos_ids, lengths, mask_time_targets in dataloader:\n",
        "    optimizer_encoder.zero_grad()\n",
        "    inputs=inputs.float().cuda()\n",
        "    time_targets = time_targets.cuda()\n",
        "    pos_ids = pos_ids.cuda()\n",
        "    mask_time_targets = mask_time_targets.cuda()\n",
        "    packed_batch=torch.nn.utils.rnn.pack_padded_sequence(inputs, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    with autocast(device_type=\"cuda\"):\n",
        "      packed_output,(ht, ct)=encoder(packed_batch)\n",
        "      output, input_sizes = pad_packed_sequence(packed_output,batch_first=True)\n",
        "      loss_classification=criterion_classification(output[:,:,:len(vocab)+2].transpose(1,2),pos_ids)\n",
        "      if epoch>=epochs_classifcation_only:\n",
        "        loss_regression=criterion_regression(F.relu(output[:,:,len(vocab)+2:]),time_targets)\n",
        "        loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "        loss=loss_classification+1e-7*loss_regression\n",
        "      else:\n",
        "        loss=loss_classification\n",
        "    loss.backward()\n",
        "    optimizer_encoder.step()\n",
        "    epoch_losses.append(loss.cpu().item())\n",
        "  loss_epoch=np.mean(epoch_losses)\n",
        "  print(\"epoch: \"+str(epoch)+\" loss: \"+str(loss_epoch))\n",
        "  train_losses.append(loss_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK6GyXpBgwNj",
        "outputId": "359ec4fd-d3e6-4f7f-bb5c-1c28d6157ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 7.769814189275106\n",
            "epoch: 1 loss: 7.688149589962429\n",
            "epoch: 2 loss: 7.681943141089546\n",
            "epoch: 3 loss: 7.677431223127577\n",
            "epoch: 4 loss: 7.672929933336046\n",
            "epoch: 5 loss: 7.673284302817451\n",
            "epoch: 6 loss: 7.6768125428093805\n",
            "epoch: 7 loss: 7.67123220761617\n",
            "epoch: 8 loss: 7.660207096735636\n",
            "epoch: 9 loss: 7.653950717714098\n",
            "epoch: 10 loss: 18.43856125937568\n",
            "epoch: 11 loss: 18.592761262257895\n",
            "epoch: 12 loss: 18.74313888549805\n",
            "epoch: 13 loss: 18.691165171729192\n",
            "epoch: 14 loss: 18.619252024756538\n",
            "epoch: 15 loss: 18.730495770772297\n",
            "epoch: 16 loss: 18.771625094943577\n",
            "epoch: 17 loss: 18.628106456332738\n",
            "epoch: 18 loss: 18.654819912380642\n",
            "epoch: 19 loss: 18.703358374701605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modified architecture"
      ],
      "metadata": {
        "id": "9athPYl3tC27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_Classification_regression(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size,output_regression_size,output_classfication_size,num_layers,batch_first=True):\n",
        "    super().__init__(self)\n",
        "    self.lstm = LSTM(input_size=input_size, hidden_size=hidden_size,batch_first=batch_first,num_layers=2)\n",
        "    self.linear_reg=nn.Linear(hidden_size,output_regression_size)\n",
        "    self.classifier=nn.Linear(hidden_size,output_classfication_size)\n",
        "  def forward(self,x,reg=True):\n",
        "    x,_=self.lstm(x)\n",
        "    x=F.relu(x)\n",
        "    if reg:\n",
        "      return self.classifier(x),self.linear_reg(x)\n",
        "    else:\n",
        "      return self.classifier(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "-z2ZjL5KxDFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "79626578-8a81-499b-fbf3-d6acb008268d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-558fd0776783>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLSTM_Classification_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_regression_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_classfication_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_regression_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding, LSTM\n",
        "import torch.nn.functional as F\n",
        "from torch import autocast\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "epochs_classifcation_only=10\n",
        "epochs_complete_problem =10\n",
        "input_size=12\n",
        "hidden_size=len(vocab)+4\n",
        "output_regression_size=2\n",
        "output_classfication_size=hidden_size-output_regression_size\n",
        "epochs=epochs_complete_problem+ epochs_classifcation_only\n",
        "model=LSTM_Classification_regression(input_size, hidden_size,output_regression_size,output_classfication_size,num_layers).cuda()\n",
        "\n",
        "optimizer_encoder = optim.Adam(encoder.parameters())\n",
        "\n",
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "train_losses=[]\n",
        "for epoch in range(epochs):\n",
        "  epoch_losses=[]\n",
        "  for x, time_targets, pos_ids, lengths, mask_time_targets in dataloader:\n",
        "    batch_size=x.shape[0]\n",
        "    optimizer_encoder.zero_grad()\n",
        "    inputs=inputs.float().cuda()\n",
        "    time_targets = time_targets.cuda()\n",
        "    pos_ids = pos_ids.cuda()\n",
        "    mask_time_targets = mask_time_targets.cuda()\n",
        "    x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    with autocast(device_type=\"cuda\"):\n",
        "      if epoch<epochs_classifcation_only:\n",
        "        x=model(x,reg=False)\n",
        "        x=pad_packed_sequence(torch.nn.utils.rnn.PackedSequence(out, batch_size), batch_first=True)\n",
        "        loss=criterion_classification(x.transpose(1,2),pos_ids)\n",
        "      else:\n",
        "        x,y=model(x,reg=True)\n",
        "        loss_classification=criterion_classification(x.transpose(1,2),pos_ids)\n",
        "        loss_regression=criterion_regression(F.relu(y),time_targets)\n",
        "        loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "        loss=loss_classification+1e-7*loss_regression\n",
        "    loss.backward()\n",
        "    optimizer_encoder.step()\n",
        "    epoch_losses.append(loss.cpu().item())\n",
        "  loss_epoch=np.mean(epoch_losses)\n",
        "  print(\"epoch: \"+str(epoch)+\" loss: \"+str(loss_epoch))\n",
        "  train_losses.append(loss_epoch)"
      ],
      "metadata": {
        "id": "3eDkPQXCtavd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ulNdz2ObMyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings\n"
      ],
      "metadata": {
        "id": "GZYv1NLSE4wD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tet1T5QoAdSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### New Dataset with  current pos_id"
      ],
      "metadata": {
        "id": "EwPa4GEsFD_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class VariableLengthDatasetWithPosID(Dataset):\n",
        "    def __init__(self, time_series, transform=None):\n",
        "        self.times_series=time_series\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.times_series)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_dict=self.times_series[idx]\n",
        "\n",
        "        return  user_dict['input'],user_dict['pos_id'],user_dict['pos_id_target'], user_dict['time_target']\n",
        "def create_dataset(list_users,split=[0.8,0.1,0.1]):\n",
        "  dataset=VariableLengthDatasetWithPosID(list_users)\n",
        "  generator = torch.Generator().manual_seed(reproducibility_seed)\n",
        "  dataset_list=torch.utils.data.random_split(dataset,[0.8,0.1,0.1],generator)\n",
        "  return dataset_list\n"
      ],
      "metadata": {
        "id": "Fza5K1w8FNUQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.times_series)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "rlK1CyN0WPAA",
        "outputId": "fd908738-ed42-4429-8caa-fb80691f0d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d56d19b6f339>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def collate_fn_padd(batch):\n",
        "    '''\n",
        "    Padds batch of variable length\n",
        "\n",
        "    note: it converts things ToTensor manually here since the ToTensor transform\n",
        "    assume it takes in images rather than arbitrary tensors.\n",
        "    '''\n",
        "    ## get sequence lengths\n",
        "    inputs,pos_ids,pos_id_targets,time_targets=zip(*batch)\n",
        "    lengths = torch.tensor([ input.shape[0] for input in inputs ])\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs,batch_first=True,padding_value=0)\n",
        "    time_targets = torch.nn.utils.rnn.pad_sequence(time_targets,batch_first=True,padding_value=-1)\n",
        "    pos_ids = torch.nn.utils.rnn.pad_sequence(pos_ids,batch_first=True,padding_value=len(vocab))\n",
        "    pos_id_targets = torch.nn.utils.rnn.pad_sequence(pos_id_targets,batch_first=True,padding_value=len(vocab))\n",
        "\n",
        "\n",
        "    return inputs, pos_ids, time_targets, pos_id_targets, lengths\n",
        "\n"
      ],
      "metadata": {
        "id": "Mb09zF7eXoR-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modified Model with embeddings"
      ],
      "metadata": {
        "id": "1HOcMohSV5AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_list=create_dataset(list_users)\n",
        "train_dataset=dataset_list[0]\n",
        "valid_dataset=dataset_list[1]\n",
        "test_dataset=dataset_list[2]\n",
        "train_dataloader=DataLoader(train_dataset,batch_size=32,collate_fn=collate_fn_padd,shuffle=True)\n",
        "valid_dataloader=DataLoader(valid_dataset,batch_size=256,collate_fn=collate_fn_padd,shuffle=False)\n",
        "test_dataloader=DataLoader(test_dataset,batch_size=256,collate_fn=collate_fn_padd,shuffle=False)"
      ],
      "metadata": {
        "id": "b5LQqag9XkFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.nn import Embedding, LSTM\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM_Classification_regression_Embeddings(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size,output_regression_size,output_classfication_size,embedding_dim,num_layers,batch_first=True):\n",
        "    super().__init__()\n",
        "    self.lstm = LSTM(input_size=input_size+embedding_dim, hidden_size=hidden_size,batch_first=batch_first,num_layers=2)\n",
        "    self.linear_reg=nn.Linear(hidden_size,output_regression_size)\n",
        "    self.classifier=nn.Linear(hidden_size,output_classfication_size)\n",
        "    self.embeddings=nn.Embedding(num_embeddings=output_classfication_size,embedding_dim=embedding_dim)\n",
        "\n",
        "  def forward(self,x,pos_id,lengths,reg=True):\n",
        "    #BEFORE: x.shape=(batch_size, max_sequence_length,input_size); pos_id.shape=(batch_size,max_sequence_length)\n",
        "    x=torch.cat([x,self.embeddings(pos_id)],dim=2)\n",
        "    #AFTER: x.shape=(batch_size, max_sequence_length, input_size+embedding_dim)\n",
        "    x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    # x.data.shape=([length_i for i in range(batch_size)].sum(),input_size+embedding_dim)\n",
        "    x,_=self.lstm(x)\n",
        "    data=F.relu(x.data)\n",
        "    if reg:\n",
        "      x = torch.nn.utils.rnn.PackedSequence(self.classifier(data), x.batch_sizes, x.sorted_indices, x.unsorted_indices)\n",
        "      y = torch.nn.utils.rnn.PackedSequence(torch.exp(self.linear_reg(data)), x.batch_sizes, x.sorted_indices, x.unsorted_indices)\n",
        "      return x,y\n",
        "    else:\n",
        "      return  torch.nn.utils.rnn.PackedSequence(self.classifier(data), x.batch_sizes, x.sorted_indices, x.unsorted_indices)"
      ],
      "metadata": {
        "id": "iu2hxoqSV4Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,dataloader,criterion_classification,criterion_regression):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc=0\n",
        "    nb_points=0\n",
        "    for x, pos_ids, time_targets, target_pos_ids, lengths in dataloader:\n",
        "      batch_size=x.shape[0]\n",
        "      x=x.float().cuda()\n",
        "      pos_ids=pos_ids.cuda()\n",
        "      time_targets = time_targets.cuda()\n",
        "      target_pos_ids = target_pos_ids.cuda()\n",
        "      with autocast(device_type=\"cuda\"):\n",
        "        x,y=model(x,pos_ids,lengths,reg=True)\n",
        "        target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(target_pos_ids, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "        time_targets=torch.nn.utils.rnn.pack_padded_sequence(time_targets, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "        ## compute mask\n",
        "        mask_time_targets = (time_targets.data != -1)\n",
        "        loss_classification=criterion_classification(x.data,target_pos_ids.data)\n",
        "        acc+=(x.data.argmax(dim=1)==target_pos_ids.data).sum()\n",
        "        nb_points+=x.data.shape[0]\n",
        "        loss_regression=criterion_regression(y.data,time_targets.data)\n",
        "        loss_regression = (loss_regression * mask_time_targets.data.float()).mean()\n",
        "        loss=loss_classification+loss_regression\n",
        "    return acc.item()/(nb_points),loss_classification.item()/len(dataloader),loss_regression.item()/len(dataloader)\n"
      ],
      "metadata": {
        "id": "lKejxmSZGhbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(valid_dataloader)*10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq1NbJJgaif4",
        "outputId": "d500dcc6-02de-4b65-a2c0-b219f0a027e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding, LSTM\n",
        "import torch.nn.functional as F\n",
        "from torch import autocast\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "## parameters\n",
        "#training params\n",
        "epochs_classifcation_only=10\n",
        "epochs_complete_problem =20\n",
        "epochs=epochs_complete_problem+ epochs_classifcation_only\n",
        "#Model params\n",
        "input_size=12\n",
        "embedding_dim=400\n",
        "num_layers=4\n",
        "hidden_size=len(vocab)+4\n",
        "output_regression_size=2\n",
        "output_classfication_size=hidden_size-output_regression_size\n",
        "\n",
        "model=LSTM_Classification_regression_Embeddings(input_size, hidden_size,output_regression_size,output_classfication_size,embedding_dim,num_layers).cuda()\n",
        "optimizer_encoder = optim.Adam(model.parameters())\n",
        "\n",
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "train_losses=[]\n",
        "valid_accs=[]\n",
        "valid_losses_classification=[]\n",
        "valid_losses_regression=[]\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  epoch_losses=[]\n",
        "  for x, pos_ids, time_targets, target_pos_ids, lengths in train_dataloader:\n",
        "    optimizer_encoder.zero_grad()\n",
        "    x=x.float().cuda()\n",
        "    pos_ids=pos_ids.cuda()\n",
        "    time_targets = time_targets.cuda()\n",
        "    #print(target_pos_ids)\n",
        "    target_pos_ids = target_pos_ids.cuda()\n",
        "    with autocast(device_type=\"cuda\"):\n",
        "      if epoch<epochs_classifcation_only:\n",
        "        x=model(x,pos_ids,lengths,reg=False)\n",
        "        target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(target_pos_ids, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "        loss=criterion_classification(x.data,target_pos_ids.data)\n",
        "      else:\n",
        "        x,y=model(x,pos_ids,lengths,reg=True)\n",
        "        target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(target_pos_ids, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "        time_targets=torch.nn.utils.rnn.pack_padded_sequence(time_targets, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "        mask_time_targets = (time_targets.data != -1)\n",
        "        loss_classification=criterion_classification(x.data,target_pos_ids.data)\n",
        "        loss_regression=criterion_regression(y.data,time_targets.data)\n",
        "        loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "        loss=loss_classification+loss_regression\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer_encoder.step()\n",
        "    epoch_losses.append(loss.cpu().item())\n",
        "  loss_epoch=np.mean(epoch_losses)\n",
        "  train_losses.append(loss_epoch)\n",
        "  valid_acc,valid_loss_classification,valid_loss_regression=evaluate(model,valid_dataloader,criterion_classification,criterion_regression)\n",
        "  valid_accs.append(valid_acc)\n",
        "  valid_losses_classification.append(valid_loss_classification)\n",
        "  valid_losses_regression.append(valid_loss_regression)\n",
        "  print(\"epoch: \"+str(epoch)+\" train loss: \"+str(loss_epoch)+\" valid_acc: \"+str(valid_acc),\" valid_loss_classification: \"+str(valid_loss_classification)+\" valid_loss_regression: \"+str(valid_loss_regression))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7LzEKFuW7kl",
        "outputId": "1d8c5842-20f2-4f06-bbac-f7aad41bac0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 train loss: 6.551205036375258 valid_acc: 0.32183010877688284  valid_loss_classification: 1.5915258725484211 valid_loss_regression: 0.6874008178710938\n",
            "epoch: 1 train loss: 3.7312705331378515 valid_acc: 0.46981649090758115  valid_loss_classification: 1.0163533687591553 valid_loss_regression: 0.6963268915812174\n",
            "epoch: 2 train loss: 2.6541660997602676 valid_acc: 0.533654405048576  valid_loss_classification: 0.7919421195983887 valid_loss_regression: 0.6965961456298828\n",
            "epoch: 3 train loss: 2.204934208922916 valid_acc: 0.5659387195881425  valid_loss_classification: 0.7073539892832438 valid_loss_regression: 0.7110209465026855\n",
            "epoch: 4 train loss: 1.986035825146569 valid_acc: 0.5732790832848957  valid_loss_classification: 0.6577861309051514 valid_loss_regression: 0.6914376417795817\n",
            "epoch: 5 train loss: 1.838186095820533 valid_acc: 0.5850369509258491  valid_loss_classification: 0.6108259359995524 valid_loss_regression: 0.6918560663859049\n",
            "epoch: 6 train loss: 1.7388380103641086 valid_acc: 0.5957817819480196  valid_loss_classification: 0.5693203210830688 valid_loss_regression: 0.6947246392567953\n",
            "epoch: 7 train loss: 1.6500097950299581 valid_acc: 0.5992692850618616  valid_loss_classification: 0.5586535135904948 valid_loss_regression: 0.6949897607167562\n",
            "epoch: 8 train loss: 1.5806961019833883 valid_acc: 0.6042846466827203  valid_loss_classification: 0.5295182863871256 valid_loss_regression: 0.6878681182861328\n",
            "epoch: 9 train loss: 1.524960368209415 valid_acc: 0.6103628663954164  valid_loss_classification: 0.5076825221379598 valid_loss_regression: 0.6863481203715006\n",
            "epoch: 10 train loss: 2.5288798173268634 valid_acc: 0.6126048326828863  valid_loss_classification: 0.4950508276621501 valid_loss_regression: 0.393752654393514\n",
            "epoch: 11 train loss: 2.432743379804823 valid_acc: 0.6123391181599269  valid_loss_classification: 0.4769328832626343 valid_loss_regression: 0.39304816722869873\n",
            "epoch: 12 train loss: 2.3807918482356603 valid_acc: 0.625940380303911  valid_loss_classification: 0.43299372990926105 valid_loss_regression: 0.39241500695546466\n",
            "epoch: 13 train loss: 2.3116112099753487 valid_acc: 0.6389603919289214  valid_loss_classification: 0.42690734068552655 valid_loss_regression: 0.3906785249710083\n",
            "epoch: 14 train loss: 2.2514840324719745 valid_acc: 0.6390434277173461  valid_loss_classification: 0.3992648124694824 valid_loss_regression: 0.3877588113149007\n",
            "epoch: 15 train loss: 2.1860368079609342 valid_acc: 0.6566470148634062  valid_loss_classification: 0.39412009716033936 valid_loss_regression: 0.38136474291483563\n",
            "epoch: 16 train loss: 2.0977391242980956 valid_acc: 0.6696504193307316  valid_loss_classification: 0.3589971462885539 valid_loss_regression: 0.3737332820892334\n",
            "epoch: 17 train loss: 2.0741467939482794 valid_acc: 0.6760939965124969  valid_loss_classification: 0.3472849527994792 valid_loss_regression: 0.4004503885904948\n",
            "epoch: 18 train loss: 1.9833597275945876 valid_acc: 0.6996263389520884  valid_loss_classification: 0.3061355749766032 valid_loss_regression: 0.3703395922978719\n",
            "epoch: 19 train loss: 1.9280816541777717 valid_acc: 0.7026986631238064  valid_loss_classification: 0.30681681632995605 valid_loss_regression: 0.3658464352289836\n",
            "epoch: 20 train loss: 1.8673170261912875 valid_acc: 0.7156522461180769  valid_loss_classification: 0.2702620029449463 valid_loss_regression: 0.35839680830637616\n",
            "epoch: 21 train loss: 1.8007817215389677 valid_acc: 0.7311799385535166  valid_loss_classification: 0.24697446823120117 valid_loss_regression: 0.4047393798828125\n",
            "epoch: 22 train loss: 1.727474025885264 valid_acc: 0.7541144233164494  valid_loss_classification: 0.2484730084737142 valid_loss_regression: 0.3559924364089966\n",
            "epoch: 23 train loss: 1.6443917923503453 valid_acc: 0.7748567632649672  valid_loss_classification: 0.21805938084920248 valid_loss_regression: 0.3502423365910848\n",
            "epoch: 24 train loss: 1.5689646151330736 valid_acc: 0.7935232085028647  valid_loss_classification: 0.17380664745966592 valid_loss_regression: 0.3364181915918986\n",
            "epoch: 25 train loss: 1.4866384347279866 valid_acc: 0.8029228597525534  valid_loss_classification: 0.16519397497177124 valid_loss_regression: 0.3407396872838338\n",
            "epoch: 26 train loss: 1.3981536176469591 valid_acc: 0.8219214481441501  valid_loss_classification: 0.13031878074010214 valid_loss_regression: 0.32941802342732746\n",
            "epoch: 27 train loss: 1.3286426067352295 valid_acc: 0.8381798555177281  valid_loss_classification: 0.12091588973999023 valid_loss_regression: 0.3274248043696086\n",
            "epoch: 28 train loss: 1.2748239292038812 valid_acc: 0.8476791497135265  valid_loss_classification: 0.10936896999677022 valid_loss_regression: 0.3190582791964213\n",
            "epoch: 29 train loss: 1.23168815308147 valid_acc: 0.8582745163165324  valid_loss_classification: 0.10815638303756714 valid_loss_regression: 0.31412885586420697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = transformer_encoder(src)"
      ],
      "metadata": {
        "id": "TjyEMoYp3dZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfomers"
      ],
      "metadata": {
        "id": "snws_Yc7JMLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Long-sequences"
      ],
      "metadata": {
        "id": "OCGyNjH0LOgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_long_sequences(list_users,max_sequence_length):\n",
        "  new_list_users=[]\n",
        "  for i in range(len(list_users)):\n",
        "    #print(i)\n",
        "    seq_length=list_users[i][\"input\"].shape[0]\n",
        "    if seq_length>=max_sequence_length:\n",
        "      div=2\n",
        "      while max_sequence_length/div >= max_sequence_length:\n",
        "        div+=1\n",
        "      new_seq_length=seq_length//div\n",
        "      list_splitted_seq=div*[{}]\n",
        "      for key in list_users[i]:\n",
        "        for j in range(div):\n",
        "          if j!=div-1:\n",
        "            list_splitted_seq[j][key]=list_users[i][key][div*j:div*(j+1)]\n",
        "          else:\n",
        "            list_splitted_seq[j][key]=list_users[i][key][div*j:]\n",
        "      new_list_users+list_splitted_seq\n",
        "    else:\n",
        "      new_list_users.append(list_users[i])\n",
        "  return new_list_users\n",
        "\n",
        "splitted_list_user=split_long_sequences(list_users,500)"
      ],
      "metadata": {
        "id": "Os929fZuLRhs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_list=create_dataset(splitted_list_user)\n",
        "train_dataset=dataset_list[0]\n",
        "valid_dataset=dataset_list[1]\n",
        "test_dataset=dataset_list[2]\n",
        "train_dataloader=DataLoader(train_dataset,batch_size=32,collate_fn=collate_fn_padd,shuffle=True)\n",
        "valid_dataloader=DataLoader(valid_dataset,batch_size=128,collate_fn=collate_fn_padd,shuffle=False)\n",
        "test_dataloader=DataLoader(test_dataset,batch_size=128,collate_fn=collate_fn_padd,shuffle=False)"
      ],
      "metadata": {
        "id": "hvVOj_aUY9Jc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import nn, Tensor\n",
        "import math\n",
        "def get_mask(bath_size,sequence_length,lengths):\n",
        "  mask=torch.zeros(bath_size,sequence_length).cuda()\n",
        "  for i, length in enumerate(lengths):\n",
        "    mask[i,length:]=1\n",
        "  return mask.bool()\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = (x.transpose(0,1) + self.pe[:x.transpose(0,1).size(0)]).transpose(0,1)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class Transformer_Classification_regression(nn.Module):\n",
        "\n",
        "  def __init__(self,embedding_dim,d_model,output_classfication_size,output_regression_size,num_layers=3,nhead=10,dropout=0.1,batch_first=True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "    encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,batch_first=True)\n",
        "    self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "    self.linear_reg=nn.Linear(d_model,output_regression_size)\n",
        "    self.classifier=nn.Linear(d_model,output_classfication_size)\n",
        "    self.embedding=nn.Embedding(num_embeddings=output_classfication_size,embedding_dim=embedding_dim)\n",
        "    self.init_weights()\n",
        "    self.d_model=d_model\n",
        "  def init_weights(self) -> None:\n",
        "    initrange = 0.1\n",
        "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "    self.classifier.bias.data.zero_()\n",
        "    self.classifier.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "  def forward(self,x,pos_id,lengths,reg=True):\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    x=torch.cat([x,self.embedding(pos_id)],dim=2)* math.sqrt(self.d_model)\n",
        "    #print(x[0,:,0])\n",
        "\n",
        "    self.pos_encoder(x)\n",
        "    with torch.no_grad():\n",
        "      mask_x = get_mask(x.shape[0],x.shape[1],lengths)\n",
        "      causal_mask=torch.nn.Transformer.generate_square_subsequent_mask(x.shape[1],device= torch.device('cuda'))\n",
        "    #print(mask_x[0])\n",
        "    #print(\"before transformers: \", torch.isnan(x).sum())\n",
        "    x=self.transformer_encoder( x,\n",
        "                        mask = causal_mask,\n",
        "                        src_key_padding_mask = mask_x,\n",
        "                        is_causal = True)\n",
        "    #print(\"after: \",torch.isnan(x).sum())\n",
        "    #print(x[0,:,0])\n",
        "    x=F.relu(x)\n",
        "    #print(x.shape,mask_x.shape)\n",
        "    #del mask_x\n",
        "    del causal_mask\n",
        "\n",
        "    if reg:\n",
        "      return self.classifier(x),torch.exp(self.linear_reg(x))\n",
        "    else:\n",
        "      return  self.classifier(x)"
      ],
      "metadata": {
        "id": "n4ZiuXfnKD0X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,dataloader,criterion_classification,criterion_regression):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc=0\n",
        "    nb_points=0\n",
        "    for x, pos_ids, time_targets, target_pos_ids, lengths in dataloader:\n",
        "      x=x.float().cuda()\n",
        "      pos_ids=pos_ids.cuda()\n",
        "      time_targets = time_targets.cuda()\n",
        "      target_pos_ids = target_pos_ids.cuda()\n",
        "      with autocast(device_type=\"cuda\"):\n",
        "        x,y=model(x,pos_ids,lengths,reg=True)\n",
        "        mask_time_targets = (time_targets != -1)\n",
        "        loss_classification=criterion_classification(x.transpose(1,2),target_pos_ids)\n",
        "        acc+=((target_pos_ids!=len(vocab))*(x.argmax(dim=2)==target_pos_ids)).sum()\n",
        "        nb_points+=lengths.sum()\n",
        "        loss_regression=criterion_regression(y,time_targets)\n",
        "        loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "        loss=loss_classification+loss_regression\n",
        "\n",
        "    return acc.item()/(nb_points),loss_classification.item()/len(dataloader),loss_regression.item()/len(dataloader)"
      ],
      "metadata": {
        "id": "t9-5-2wcZGg9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)+2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66sm12PjuiYp",
        "outputId": "c40265b0-c1d4-49af-e784-9fe3ddb73170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2773"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defgh1VqiZzw",
        "outputId": "8cde39df-5474-4c96-ba3b-142444efa300"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1846327808"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import Embedding, LSTM\n",
        "import torch.nn.functional as F\n",
        "from torch import autocast\n",
        "import numpy as np\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "## parameters\n",
        "#training params\n",
        "\n",
        "epochs_classifcation_only=20\n",
        "epochs_complete_problem =10\n",
        "epochs=epochs_complete_problem+ epochs_classifcation_only\n",
        "#Model params\n",
        "nhead=10\n",
        "num_layers=2\n",
        "d_model=2780\n",
        "\n",
        "input_size=12\n",
        "output_regression_size=2\n",
        "output_classfication_size=len(vocab)+2\n",
        "embedding_dim=d_model-input_size\n",
        "\n",
        "model=Transformer_Classification_regression(embedding_dim,\n",
        "                                            d_model,\n",
        "                                            output_classfication_size,\n",
        "                                            output_regression_size,\n",
        "                                            num_layers,\n",
        "                                            nhead\n",
        "                                            ).cuda()\n",
        "lr=5e-4\n",
        "optimizer_encoder = optim.Adam(model.parameters(),lr=lr)\n",
        "\n",
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index = len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction = 'none')\n",
        "\n",
        "train_losses=[]\n",
        "valid_accs=[]\n",
        "valid_losses_classification=[]\n",
        "valid_losses_regression=[]\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  epoch_losses=[]\n",
        "  for x, pos_ids, time_targets, target_pos_ids, lengths in train_dataloader:\n",
        "\n",
        "    optimizer_encoder.zero_grad()\n",
        "    x=x.float().cuda()\n",
        "    pos_ids=pos_ids.cuda()\n",
        "    target_pos_ids = target_pos_ids.cuda()\n",
        "\n",
        "    with autocast(device_type=\"cuda\"):\n",
        "\n",
        "      if epoch<epochs_classifcation_only:\n",
        "        #print(torch.isnan(x).sum())\n",
        "        x=model(x,pos_ids,lengths,reg=False)\n",
        "        #print(torch.isnan(x).sum())\n",
        "        loss=criterion_classification(x.transpose(1,2),target_pos_ids)\n",
        "        #print(loss)\n",
        "        #break\n",
        "      else:\n",
        "        time_targets = time_targets.cuda()\n",
        "        x,y=model(x,pos_ids,lengths,reg=True)\n",
        "        mask_time_targets = (time_targets != -1)\n",
        "        loss_classification=criterion_classification(x.transpose(1,2),target_pos_ids)\n",
        "        loss_regression=criterion_regression(y,time_targets)\n",
        "        loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "        loss=loss_classification+loss_regression\n",
        "    loss.backward()\n",
        "    optimizer_encoder.step()\n",
        "    epoch_losses.append(loss.cpu().item())\n",
        "\n",
        "    del loss\n",
        "    del x\n",
        "    del pos_ids\n",
        "    del target_pos_ids\n",
        "  #break\n",
        "  loss_epoch=np.mean(epoch_losses)\n",
        "  train_losses.append(loss_epoch)\n",
        "\n",
        "  valid_acc,valid_loss_classification,valid_loss_regression=evaluate(model,valid_dataloader,criterion_classification,criterion_regression)\n",
        "  valid_accs.append(valid_acc)\n",
        "  valid_losses_classification.append(valid_loss_classification)\n",
        "  valid_losses_regression.append(valid_loss_regression)\n",
        "  print(\"epoch: \"+str(epoch)+\" train loss: \"+str(loss_epoch)+\" valid_acc: \"+str(valid_acc),\" valid_loss_classification: \"+str(valid_loss_classification)+\" valid_loss_regression: \"+str(valid_loss_regression))"
      ],
      "metadata": {
        "id": "g2OBg3tR3T54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f8b190-13ef-491a-d495-f226691aed70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 train loss: 8.239769121983668 valid_acc: tensor(0.0129)  valid_loss_classification: 1.5951584815979003 valid_loss_regression: 0.12317827939987183\n",
            "epoch: 1 train loss: 6.946030696788868 valid_acc: tensor(0.1128)  valid_loss_classification: 1.3558566093444824 valid_loss_regression: 0.12690681219100952\n",
            "epoch: 2 train loss: 5.482921546989387 valid_acc: tensor(0.1789)  valid_loss_classification: 1.1733293533325195 valid_loss_regression: 0.12059834003448486\n",
            "epoch: 3 train loss: 4.392017831335535 valid_acc: tensor(0.1999)  valid_loss_classification: 1.0548426628112793 valid_loss_regression: 0.12448951005935668\n",
            "epoch: 4 train loss: 3.7885432810216515 valid_acc: tensor(0.2310)  valid_loss_classification: 1.0873330116271973 valid_loss_regression: 0.11788644790649414\n",
            "epoch: 5 train loss: 3.5132322478127644 valid_acc: tensor(0.2430)  valid_loss_classification: 0.9962759017944336 valid_loss_regression: 0.13220565319061278\n",
            "epoch: 6 train loss: 3.200424827895798 valid_acc: tensor(0.2613)  valid_loss_classification: 0.9304627418518067 valid_loss_regression: 0.1256321430206299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTvfkslILz5J",
        "outputId": "25a2f861-abc5-4a11-cc88-a1a76031701f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "Hqm1HmoJMqvZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del optimizer_encoder\n",
        "#del model\n",
        "del x\n"
      ],
      "metadata": {
        "id": "Z7kfgfhQjARD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del loss\n",
        "\n",
        "del pos_ids\n",
        "del target_pos_ids"
      ],
      "metadata": {
        "id": "xKtEIF0ckCdY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for x, pos_ids, time_targets, target_pos_ids, lengths in train_dataloader:\n",
        "    x=x.float().cuda()\n",
        "    pos_ids=pos_ids.cuda()\n",
        "    time_targets = time_targets.cuda()\n",
        "    target_pos_ids = target_pos_ids.cuda()\n",
        "    with autocast(device_type=\"cuda\"):\n",
        "        x,y=model(x,pos_ids,lengths,reg=True)\n",
        "        print(((x.argmax(dim=2)==target_pos_ids))[0],target_pos_ids)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDfzS6frHBAD",
        "outputId": "bfe06a7c-99fb-4c35-8ad7-fddd89747e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False,  True, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False], device='cuda:0') tensor([[ 558,  558,  558,  ..., 2771, 2771, 2771],\n",
            "        [ 938,  185,  185,  ..., 2771, 2771, 2771],\n",
            "        [ 704,  704,  444,  ..., 2771, 2771, 2771],\n",
            "        ...,\n",
            "        [ 415,  754,  955,  ..., 2771, 2771, 2771],\n",
            "        [1139, 1139, 1139,  ..., 2771, 2771, 2771],\n",
            "        [ 526,  526,  320,  ..., 2771, 2771, 2771]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2grM08lHyrb",
        "outputId": "1e5aa786-7996-4d54-f5e0-bd9900a624b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2771"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost\n"
      ],
      "metadata": {
        "id": "KZJtqD0TqY_z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_VzUlsfqjZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3IUYe_BnqX8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hg_bdCUbHAdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "9m0XhmAMglzb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfE7AaJVgjkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "5M0WdUqorLal",
        "outputId": "54567bb9-d7ee-40d6-8650-78b7a4da5f86"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "grouped_id=df_xlsx.groupby('location(latitude/lontitude)')\n",
        "i=0\n",
        "for id,df_id in grouped_id:\n",
        "  #print(id)\n",
        "  (df_id.groupby([df_id[\"start time\"].dt.hour])[\"start time\"].count()/15).plot()\n",
        "  i+=1\n",
        "  break\n",
        "  if i>=1000:\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cfHKdIGzKKT"
      },
      "outputs": [],
      "source": [
        "dataset_dic=np.load(\"./TelecomDataset/dataset_dic.npy\",allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oTTDREJGA2E"
      },
      "outputs": [],
      "source": [
        "dataset_dic=delete_overlaps_dataset(dataset_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YODEtdaU7_H2"
      },
      "outputs": [],
      "source": [
        "dataset_dic, list_id = convervt_id_to_idx(dataset_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi1W0MIeHMEv"
      },
      "outputs": [],
      "source": [
        "dic_station, list_station=get_dic_station(dataset_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXFrBrX1QS28"
      },
      "outputs": [],
      "source": [
        "dataset_dic=add_class(dataset_dic,dic_station)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL4QbuX0HIDC"
      },
      "outputs": [],
      "source": [
        "idx=2\n",
        "start_times=dataset_dic[idx][\"start time\"]\n",
        "end_times=dataset_dic[idx][\"end time\"]\n",
        "nb_time_step_connections=((end_times-start_times).astype('timedelta64[m]')//15)\n",
        "nb_time_step_btwn_connections=((end_times[1:]-start_times[:-1]).astype('timedelta64[m]')//15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwihgPdFHSd6"
      },
      "outputs": [],
      "source": [
        "print(nb_time_step_connections,nb_time_step_btwn_connections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THK-1nVFigRo"
      },
      "outputs": [],
      "source": [
        "mean=get_mean_connect_time(dataset_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lH2mV4VfOm_",
        "outputId": "74995689-13fa-4443-e952-e75d938c9aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22 minutes\n"
          ]
        }
      ],
      "source": [
        "print((dataset_dic[2]['end time'][0]-dataset_dic[2]['start time'][0]).astype('timedelta64[m]'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdyuWUHpAnr-",
        "outputId": "7cb37c24-cb0c-4cb8-e947-ba3f98f23374"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.arange(100).reshape(10,10).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDnBVkDu1MnK"
      },
      "outputs": [],
      "source": [
        "def blank_name(dataset_dic,idx)\n",
        "    start_times=dataset_dic[idx][\"start time\"]\n",
        "    end_times=dataset_dic[idx][\"end time\"]\n",
        "    nb_time_step_connections=((end_times-start_times).astype('timedelta64[m]')//15).int()\n",
        "    nb_time_step_btwn_connections=((end_times[1:]-start_times[:-1]).astype('timedelta64[m]')//15).int()\n",
        "    repmat(\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "sFXniIO_obpi",
        "outputId": "453f0bb4-60d9-4c50-b836-1eda96766d97"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e04d0e47917e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTimeSeriesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mPyTorch\u001b[0m \u001b[0mDataset\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mseries\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for the time series data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_dic, input_sequence_len, output_size=1, nan_started=0, nan_stopped=0, missing_indices=np.array([])):\n",
        "        self.data = dataset_dic\n",
        "        self.input_sequence_len = input_sequence_len\n",
        "        self.output_size = output_size\n",
        "        self.nan_started = nan_started\n",
        "        self.missing_data_len = nan_stopped - nan_started\n",
        "        self.missing_indices = missing_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - 2*self.input_sequence_len - 2*self.output_size - self.missing_data_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        self.data =\n",
        "        dic_idx= self.data[idx]\n",
        "        =dic_idx['start time']\n",
        "        stop_sequence_idx = start_idx + self.input_sequence_len\n",
        "        stop_target_idx = stop_sequence_idx + self.output_size\n",
        "        # If considered sequence intersects with the missing value list [11122, .... ,11133]\n",
        "        # jump to 11134 index\n",
        "        if np.intersect1d(np.arange(start_idx, stop_target_idx), self.missing_indices).size > 0:\n",
        "          start_idx = self.missing_indices[-1] + 1\n",
        "\n",
        "        # Avoid the missing data range\n",
        "        if stop_target_idx >= self.nan_started :\n",
        "            start_idx += self.missing_data_len + self.input_sequence_len + self.output_size\n",
        "            stop_sequence_idx = start_idx + self.input_sequence_len\n",
        "            stop_target_idx = stop_sequence_idx + self.output_size\n",
        "        # Extracting a sequence of data\n",
        "        # YOUR CODE HERE\n",
        "        assert sequence.shape[0] == self.input_sequence_len\n",
        "        assert target.shape[0] == self.output_size\n",
        "        return {'sequence': torch.Tensor(sequence), 'target': torch.Tensor(target)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "eJEiHzQTlMsK",
        "outputId": "b5a9a061-5ecd-4930-a1eb-fb53621dae4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 6943182 0 0\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-2b694dc25841>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not sorted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdataset_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bb7536ef8ccd0fc2c8cddd9102e0d580'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mdataset_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bb7536ef8ccd0fc2c8cddd9102e0d580'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'bb7536ef8ccd0fc2c8cddd9102e0d580'"
          ]
        }
      ],
      "source": [
        "nb=0\n",
        "nb2=0\n",
        "nb3=0\n",
        "nb4=0\n",
        "for id in dataset_dic:\n",
        "  dic_id=dataset_dic[id]\n",
        "  startarray=dic_id['start time']\n",
        "  endarray=dic_id['end time']\n",
        "  lattitude_array=dic_id['latitude']\n",
        "  for i in range(len(startarray)-1):\n",
        "    if startarray[i]>endarray[i]:\n",
        "      nb4+=0\n",
        "      print(\"element :\"+str(i)+\" of id: \"+id)\n",
        "    if startarray[i+1]<endarray[i]:\n",
        "      nb+=1\n",
        "    else:\n",
        "      nb2+=1\n",
        "    if startarray[i+1]<endarray[i] and lattitude_array[i]!=lattitude_array[i+1]:\n",
        "      nb3+=1\n",
        "    if startarray[i+1]<startarray[i]:\n",
        "      nb+=0\n",
        "      print(\"not sorted\")\n",
        "print(nb,nb2,nb3,nb4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "towO0Z_Tjm-z",
        "outputId": "8265f354-8358-4ad7-8a18-8d8f774fd7ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "keXO_RhYNbXN",
        "outputId": "37e870ea-985d-4495-ee7d-c6d2cba74652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        month  date          start time            end time   latitude  \\\n",
            "205        10    16 2014-10-16 11:44:35 2014-10-16 11:53:03  31.246946   \n",
            "206        10    16 2014-10-16 12:08:07 2014-10-16 12:18:56  31.246946   \n",
            "207        10    16 2014-10-16 08:59:32 2014-10-16 11:00:51  31.246946   \n",
            "208        10    16 2014-10-16 14:29:49 2014-10-16 14:43:32  31.246946   \n",
            "209        10    16 2014-10-16 16:08:41 2014-10-16 16:11:17  31.246946   \n",
            "...       ...   ...                 ...                 ...        ...   \n",
            "575569     10    31 2014-10-31 14:57:37 2014-10-31 15:01:11  31.087196   \n",
            "575570     10    31 2014-10-31 14:46:40 2014-10-31 14:48:38  31.087196   \n",
            "575571     10    31 2014-10-31 15:12:59 2014-10-31 15:14:27  31.087196   \n",
            "575572     10    31 2014-10-31 16:59:06 2014-10-31 17:00:30  31.087196   \n",
            "575573     10    31 2014-10-31 15:17:47 2014-10-31 15:19:46  31.087196   \n",
            "\n",
            "        longitude                           user id  day  hour  minute  ...  \\\n",
            "205      0.654516  b6f11a26170aabb49062f79b03818bf2   16    11      44  ...   \n",
            "206      0.654516  b6f11a26170aabb49062f79b03818bf2   16    12       8  ...   \n",
            "207      0.654516  c150c622280f1d6e32dd45e7c59ed751   16     8      59  ...   \n",
            "208      0.654516  b6f11a26170aabb49062f79b03818bf2   16    14      29  ...   \n",
            "209      0.654516  b6f11a26170aabb49062f79b03818bf2   16    16       8  ...   \n",
            "...           ...                               ...  ...   ...     ...  ...   \n",
            "575569   0.654231  ec4591ee193aa81f11e60f1962d472df   31    14      57  ...   \n",
            "575570   0.654231  ec4591ee193aa81f11e60f1962d472df   31    14      46  ...   \n",
            "575571   0.654231  ec4591ee193aa81f11e60f1962d472df   31    15      12  ...   \n",
            "575572   0.654231  ec4591ee193aa81f11e60f1962d472df   31    16      59  ...   \n",
            "575573   0.654231  ec4591ee193aa81f11e60f1962d472df   31    15      17  ...   \n",
            "\n",
            "        month_cos   day_sin   day_cos      hour_sin  hour_cos  minute_sin  \\\n",
            "205           0.5  0.790776 -0.612106  2.588190e-01 -0.965926    0.913545   \n",
            "206           0.5  0.651372 -0.758758  1.224647e-16 -1.000000    0.951057   \n",
            "207           0.5  0.998717 -0.050649  8.660254e-01 -0.500000    0.743145   \n",
            "208           0.5  0.299363 -0.954139 -5.000000e-01 -0.866025    0.994522   \n",
            "209           0.5 -0.101168 -0.994869 -8.660254e-01 -0.500000    0.994522   \n",
            "...           ...       ...       ...           ...       ...         ...   \n",
            "575569        0.5  0.299363 -0.954139 -5.000000e-01 -0.866025    0.994522   \n",
            "575570        0.5  0.299363 -0.954139 -5.000000e-01 -0.866025    0.994522   \n",
            "575571        0.5  0.101168 -0.994869 -7.071068e-01 -0.707107    1.000000   \n",
            "575572        0.5 -0.101168 -0.994869 -8.660254e-01 -0.500000    0.994522   \n",
            "575573        0.5  0.101168 -0.994869 -7.071068e-01 -0.707107    1.000000   \n",
            "\n",
            "          minute_cos  second_sin    second_cos  latitute  \n",
            "205     4.067366e-01    0.913545  4.067366e-01  0.359689  \n",
            "206     3.090170e-01    0.951057  3.090170e-01  0.359689  \n",
            "207     6.691306e-01    0.743145  6.691306e-01  0.359689  \n",
            "208     1.045285e-01    0.994522  1.045285e-01  0.359689  \n",
            "209    -1.045285e-01    0.994522 -1.045285e-01  0.359689  \n",
            "...              ...         ...           ...       ...  \n",
            "575569  1.045285e-01    0.994522  1.045285e-01  0.353103  \n",
            "575570  1.045285e-01    0.994522  1.045285e-01  0.353103  \n",
            "575571  2.832769e-16    1.000000  2.832769e-16  0.353103  \n",
            "575572 -1.045285e-01    0.994522 -1.045285e-01  0.353103  \n",
            "575573  2.832769e-16    1.000000  2.832769e-16  0.353103  \n",
            "\n",
            "[511890 rows x 23 columns]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cc454076-3304-4bf3-b4d4-474aad6f191d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start time</th>\n",
              "      <th>end time</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>user id</th>\n",
              "      <th>day</th>\n",
              "      <th>month_sin</th>\n",
              "      <th>month_cos</th>\n",
              "      <th>day_sin</th>\n",
              "      <th>day_cos</th>\n",
              "      <th>hour_sin</th>\n",
              "      <th>hour_cos</th>\n",
              "      <th>minute_sin</th>\n",
              "      <th>minute_cos</th>\n",
              "      <th>second_sin</th>\n",
              "      <th>second_cos</th>\n",
              "      <th>latitute</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>2014-10-16 11:44:35</td>\n",
              "      <td>2014-10-16 11:53:03</td>\n",
              "      <td>0.359689</td>\n",
              "      <td>0.654516</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.790776</td>\n",
              "      <td>-0.612106</td>\n",
              "      <td>2.588190e-01</td>\n",
              "      <td>-0.965926</td>\n",
              "      <td>0.913545</td>\n",
              "      <td>4.067366e-01</td>\n",
              "      <td>0.913545</td>\n",
              "      <td>4.067366e-01</td>\n",
              "      <td>0.359689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>2014-10-16 12:08:07</td>\n",
              "      <td>2014-10-16 12:18:56</td>\n",
              "      <td>0.359689</td>\n",
              "      <td>0.654516</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.651372</td>\n",
              "      <td>-0.758758</td>\n",
              "      <td>1.224647e-16</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.951057</td>\n",
              "      <td>3.090170e-01</td>\n",
              "      <td>0.951057</td>\n",
              "      <td>3.090170e-01</td>\n",
              "      <td>0.359689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>2014-10-16 08:59:32</td>\n",
              "      <td>2014-10-16 11:00:51</td>\n",
              "      <td>0.359689</td>\n",
              "      <td>0.654516</td>\n",
              "      <td>c150c622280f1d6e32dd45e7c59ed751</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.998717</td>\n",
              "      <td>-0.050649</td>\n",
              "      <td>8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.743145</td>\n",
              "      <td>6.691306e-01</td>\n",
              "      <td>0.743145</td>\n",
              "      <td>6.691306e-01</td>\n",
              "      <td>0.359689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>2014-10-16 14:29:49</td>\n",
              "      <td>2014-10-16 14:43:32</td>\n",
              "      <td>0.359689</td>\n",
              "      <td>0.654516</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.299363</td>\n",
              "      <td>-0.954139</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>1.045285e-01</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>1.045285e-01</td>\n",
              "      <td>0.359689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>2014-10-16 16:08:41</td>\n",
              "      <td>2014-10-16 16:11:17</td>\n",
              "      <td>0.359689</td>\n",
              "      <td>0.654516</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.101168</td>\n",
              "      <td>-0.994869</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>-1.045285e-01</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>-1.045285e-01</td>\n",
              "      <td>0.359689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575569</th>\n",
              "      <td>2014-10-31 14:57:37</td>\n",
              "      <td>2014-10-31 15:01:11</td>\n",
              "      <td>0.353103</td>\n",
              "      <td>0.654231</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "      <td>31</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.299363</td>\n",
              "      <td>-0.954139</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>1.045285e-01</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>1.045285e-01</td>\n",
              "      <td>0.353103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575570</th>\n",
              "      <td>2014-10-31 14:46:40</td>\n",
              "      <td>2014-10-31 14:48:38</td>\n",
              "      <td>0.353103</td>\n",
              "      <td>0.654231</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "      <td>31</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.299363</td>\n",
              "      <td>-0.954139</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>1.045285e-01</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>1.045285e-01</td>\n",
              "      <td>0.353103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575571</th>\n",
              "      <td>2014-10-31 15:12:59</td>\n",
              "      <td>2014-10-31 15:14:27</td>\n",
              "      <td>0.353103</td>\n",
              "      <td>0.654231</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "      <td>31</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.101168</td>\n",
              "      <td>-0.994869</td>\n",
              "      <td>-7.071068e-01</td>\n",
              "      <td>-0.707107</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.832769e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.832769e-16</td>\n",
              "      <td>0.353103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575572</th>\n",
              "      <td>2014-10-31 16:59:06</td>\n",
              "      <td>2014-10-31 17:00:30</td>\n",
              "      <td>0.353103</td>\n",
              "      <td>0.654231</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "      <td>31</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.101168</td>\n",
              "      <td>-0.994869</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>-1.045285e-01</td>\n",
              "      <td>0.994522</td>\n",
              "      <td>-1.045285e-01</td>\n",
              "      <td>0.353103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575573</th>\n",
              "      <td>2014-10-31 15:17:47</td>\n",
              "      <td>2014-10-31 15:19:46</td>\n",
              "      <td>0.353103</td>\n",
              "      <td>0.654231</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "      <td>31</td>\n",
              "      <td>-0.866025</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.101168</td>\n",
              "      <td>-0.994869</td>\n",
              "      <td>-7.071068e-01</td>\n",
              "      <td>-0.707107</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.832769e-16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.832769e-16</td>\n",
              "      <td>0.353103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>511890 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc454076-3304-4bf3-b4d4-474aad6f191d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc454076-3304-4bf3-b4d4-474aad6f191d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc454076-3304-4bf3-b4d4-474aad6f191d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7ecdda7-fa94-46b6-9ef8-5e16ef84ae1e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7ecdda7-fa94-46b6-9ef8-5e16ef84ae1e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7ecdda7-fa94-46b6-9ef8-5e16ef84ae1e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                start time            end time  latitude  longitude  \\\n",
              "205    2014-10-16 11:44:35 2014-10-16 11:53:03  0.359689   0.654516   \n",
              "206    2014-10-16 12:08:07 2014-10-16 12:18:56  0.359689   0.654516   \n",
              "207    2014-10-16 08:59:32 2014-10-16 11:00:51  0.359689   0.654516   \n",
              "208    2014-10-16 14:29:49 2014-10-16 14:43:32  0.359689   0.654516   \n",
              "209    2014-10-16 16:08:41 2014-10-16 16:11:17  0.359689   0.654516   \n",
              "...                    ...                 ...       ...        ...   \n",
              "575569 2014-10-31 14:57:37 2014-10-31 15:01:11  0.353103   0.654231   \n",
              "575570 2014-10-31 14:46:40 2014-10-31 14:48:38  0.353103   0.654231   \n",
              "575571 2014-10-31 15:12:59 2014-10-31 15:14:27  0.353103   0.654231   \n",
              "575572 2014-10-31 16:59:06 2014-10-31 17:00:30  0.353103   0.654231   \n",
              "575573 2014-10-31 15:17:47 2014-10-31 15:19:46  0.353103   0.654231   \n",
              "\n",
              "                                 user id  day  month_sin  month_cos   day_sin  \\\n",
              "205     b6f11a26170aabb49062f79b03818bf2   16  -0.866025        0.5  0.790776   \n",
              "206     b6f11a26170aabb49062f79b03818bf2   16  -0.866025        0.5  0.651372   \n",
              "207     c150c622280f1d6e32dd45e7c59ed751   16  -0.866025        0.5  0.998717   \n",
              "208     b6f11a26170aabb49062f79b03818bf2   16  -0.866025        0.5  0.299363   \n",
              "209     b6f11a26170aabb49062f79b03818bf2   16  -0.866025        0.5 -0.101168   \n",
              "...                                  ...  ...        ...        ...       ...   \n",
              "575569  ec4591ee193aa81f11e60f1962d472df   31  -0.866025        0.5  0.299363   \n",
              "575570  ec4591ee193aa81f11e60f1962d472df   31  -0.866025        0.5  0.299363   \n",
              "575571  ec4591ee193aa81f11e60f1962d472df   31  -0.866025        0.5  0.101168   \n",
              "575572  ec4591ee193aa81f11e60f1962d472df   31  -0.866025        0.5 -0.101168   \n",
              "575573  ec4591ee193aa81f11e60f1962d472df   31  -0.866025        0.5  0.101168   \n",
              "\n",
              "         day_cos      hour_sin  hour_cos  minute_sin    minute_cos  \\\n",
              "205    -0.612106  2.588190e-01 -0.965926    0.913545  4.067366e-01   \n",
              "206    -0.758758  1.224647e-16 -1.000000    0.951057  3.090170e-01   \n",
              "207    -0.050649  8.660254e-01 -0.500000    0.743145  6.691306e-01   \n",
              "208    -0.954139 -5.000000e-01 -0.866025    0.994522  1.045285e-01   \n",
              "209    -0.994869 -8.660254e-01 -0.500000    0.994522 -1.045285e-01   \n",
              "...          ...           ...       ...         ...           ...   \n",
              "575569 -0.954139 -5.000000e-01 -0.866025    0.994522  1.045285e-01   \n",
              "575570 -0.954139 -5.000000e-01 -0.866025    0.994522  1.045285e-01   \n",
              "575571 -0.994869 -7.071068e-01 -0.707107    1.000000  2.832769e-16   \n",
              "575572 -0.994869 -8.660254e-01 -0.500000    0.994522 -1.045285e-01   \n",
              "575573 -0.994869 -7.071068e-01 -0.707107    1.000000  2.832769e-16   \n",
              "\n",
              "        second_sin    second_cos  latitute  \n",
              "205       0.913545  4.067366e-01  0.359689  \n",
              "206       0.951057  3.090170e-01  0.359689  \n",
              "207       0.743145  6.691306e-01  0.359689  \n",
              "208       0.994522  1.045285e-01  0.359689  \n",
              "209       0.994522 -1.045285e-01  0.359689  \n",
              "...            ...           ...       ...  \n",
              "575569    0.994522  1.045285e-01  0.353103  \n",
              "575570    0.994522  1.045285e-01  0.353103  \n",
              "575571    1.000000  2.832769e-16  0.353103  \n",
              "575572    0.994522 -1.045285e-01  0.353103  \n",
              "575573    1.000000  2.832769e-16  0.353103  \n",
              "\n",
              "[511890 rows x 17 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "df=df.loc[np.isnan(df['latitude'])==False]\n",
        "print(df)\n",
        "\n",
        "df['month'] = df[\"start time\"].dt.month\n",
        "df['day'] = df[\"start time\"].dt.day\n",
        "df['hour'] = df[\"start time\"].dt.hour\n",
        "df['minute'] = df[\"start time\"].dt.minute\n",
        "df['second'] = df[\"start time\"].dt.second\n",
        "df['year'] = df[\"start time\"].dt.year\n",
        "\n",
        "df_encoded = df\n",
        "\n",
        "df_encoded['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "df_encoded['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "\n",
        "df_encoded['day_sin'] = np.sin(2 * np.pi * df['hour'] / 31)\n",
        "df_encoded['day_cos'] = np.cos(2 * np.pi * df['hour'] / 31)\n",
        "\n",
        "df_encoded['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "df_encoded['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "\n",
        "df_encoded['minute_sin'] = np.sin(2 * np.pi * df['hour'] / 60)\n",
        "df_encoded['minute_cos'] = np.cos(2 * np.pi * df['hour'] / 60)\n",
        "\n",
        "df_encoded['second_sin'] = np.sin(2 * np.pi * df['hour'] / 60)\n",
        "df_encoded['second_cos'] = np.cos(2 * np.pi * df['hour'] / 60)\n",
        "\n",
        "# Normalise the temperatures into a range of [0, 1],\n",
        "# to ensure that all input features are on a similar scale\n",
        "min_latitude = df_encoded['latitude'].min()\n",
        "max_latitude = df_encoded['latitude'].max()\n",
        "df_encoded['latitude'] = (df_encoded['latitude'] - min_latitude) / (max_latitude - min_latitude)\n",
        "\n",
        "min_latitude = df_encoded['longitude'].min()\n",
        "max_latitude = df_encoded['longitude'].max()\n",
        "df_encoded['longitude'] = (df_encoded['longitude'] - min_latitude) / (max_latitude - min_latitude)\n",
        "\n",
        "# Remove unused columns\n",
        "columns_to_drop = ['year','month','hour','second','minute','date']\n",
        "df_encoded = df_encoded.drop(columns=columns_to_drop, axis=1)\n",
        "df_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81mZW17LG_rF",
        "outputId": "d9d8c016-68a7-495c-a0fb-74db4288ca4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.float64(\"Nan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_ZQ59NFMX0W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "XTGp_VX8Lw5w",
        "outputId": "5e68087c-6d25-4cf4-92b3-2666b2ea916f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44fa6ada-7e85-48d2-b80b-3bc827e7e19e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>start time</th>\n",
              "      <th>end time</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>user id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>201410</td>\n",
              "      <td>16</td>\n",
              "      <td>2014-10-16 11:44:35</td>\n",
              "      <td>2014-10-16 11:53:03</td>\n",
              "      <td>31.246946</td>\n",
              "      <td>121.513919</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>201410</td>\n",
              "      <td>16</td>\n",
              "      <td>2014-10-16 12:08:07</td>\n",
              "      <td>2014-10-16 12:18:56</td>\n",
              "      <td>31.246946</td>\n",
              "      <td>121.513919</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>201410</td>\n",
              "      <td>16</td>\n",
              "      <td>2014-10-16 08:59:32</td>\n",
              "      <td>2014-10-16 11:00:51</td>\n",
              "      <td>31.246946</td>\n",
              "      <td>121.513919</td>\n",
              "      <td>c150c622280f1d6e32dd45e7c59ed751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>201410</td>\n",
              "      <td>16</td>\n",
              "      <td>2014-10-16 14:29:49</td>\n",
              "      <td>2014-10-16 14:43:32</td>\n",
              "      <td>31.246946</td>\n",
              "      <td>121.513919</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>201410</td>\n",
              "      <td>16</td>\n",
              "      <td>2014-10-16 16:08:41</td>\n",
              "      <td>2014-10-16 16:11:17</td>\n",
              "      <td>31.246946</td>\n",
              "      <td>121.513919</td>\n",
              "      <td>b6f11a26170aabb49062f79b03818bf2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575569</th>\n",
              "      <td>201410</td>\n",
              "      <td>31</td>\n",
              "      <td>2014-10-31 14:57:37</td>\n",
              "      <td>2014-10-31 15:01:11</td>\n",
              "      <td>31.087196</td>\n",
              "      <td>121.505435</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575570</th>\n",
              "      <td>201410</td>\n",
              "      <td>31</td>\n",
              "      <td>2014-10-31 14:46:40</td>\n",
              "      <td>2014-10-31 14:48:38</td>\n",
              "      <td>31.087196</td>\n",
              "      <td>121.505435</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575571</th>\n",
              "      <td>201410</td>\n",
              "      <td>31</td>\n",
              "      <td>2014-10-31 15:12:59</td>\n",
              "      <td>2014-10-31 15:14:27</td>\n",
              "      <td>31.087196</td>\n",
              "      <td>121.505435</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575572</th>\n",
              "      <td>201410</td>\n",
              "      <td>31</td>\n",
              "      <td>2014-10-31 16:59:06</td>\n",
              "      <td>2014-10-31 17:00:30</td>\n",
              "      <td>31.087196</td>\n",
              "      <td>121.505435</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575573</th>\n",
              "      <td>201410</td>\n",
              "      <td>31</td>\n",
              "      <td>2014-10-31 15:17:47</td>\n",
              "      <td>2014-10-31 15:19:46</td>\n",
              "      <td>31.087196</td>\n",
              "      <td>121.505435</td>\n",
              "      <td>ec4591ee193aa81f11e60f1962d472df</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>511890 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44fa6ada-7e85-48d2-b80b-3bc827e7e19e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44fa6ada-7e85-48d2-b80b-3bc827e7e19e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44fa6ada-7e85-48d2-b80b-3bc827e7e19e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff01ff28-d09a-4ecf-8870-5d25d5aece4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff01ff28-d09a-4ecf-8870-5d25d5aece4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff01ff28-d09a-4ecf-8870-5d25d5aece4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         month  date          start time            end time   latitude  \\\n",
              "205     201410    16 2014-10-16 11:44:35 2014-10-16 11:53:03  31.246946   \n",
              "206     201410    16 2014-10-16 12:08:07 2014-10-16 12:18:56  31.246946   \n",
              "207     201410    16 2014-10-16 08:59:32 2014-10-16 11:00:51  31.246946   \n",
              "208     201410    16 2014-10-16 14:29:49 2014-10-16 14:43:32  31.246946   \n",
              "209     201410    16 2014-10-16 16:08:41 2014-10-16 16:11:17  31.246946   \n",
              "...        ...   ...                 ...                 ...        ...   \n",
              "575569  201410    31 2014-10-31 14:57:37 2014-10-31 15:01:11  31.087196   \n",
              "575570  201410    31 2014-10-31 14:46:40 2014-10-31 14:48:38  31.087196   \n",
              "575571  201410    31 2014-10-31 15:12:59 2014-10-31 15:14:27  31.087196   \n",
              "575572  201410    31 2014-10-31 16:59:06 2014-10-31 17:00:30  31.087196   \n",
              "575573  201410    31 2014-10-31 15:17:47 2014-10-31 15:19:46  31.087196   \n",
              "\n",
              "         longitude                           user id  \n",
              "205     121.513919  b6f11a26170aabb49062f79b03818bf2  \n",
              "206     121.513919  b6f11a26170aabb49062f79b03818bf2  \n",
              "207     121.513919  c150c622280f1d6e32dd45e7c59ed751  \n",
              "208     121.513919  b6f11a26170aabb49062f79b03818bf2  \n",
              "209     121.513919  b6f11a26170aabb49062f79b03818bf2  \n",
              "...            ...                               ...  \n",
              "575569  121.505435  ec4591ee193aa81f11e60f1962d472df  \n",
              "575570  121.505435  ec4591ee193aa81f11e60f1962d472df  \n",
              "575571  121.505435  ec4591ee193aa81f11e60f1962d472df  \n",
              "575572  121.505435  ec4591ee193aa81f11e60f1962d472df  \n",
              "575573  121.505435  ec4591ee193aa81f11e60f1962d472df  \n",
              "\n",
              "[511890 rows x 7 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[np.isnan(df['latitude'])==False]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTlEgTOZnrmC"
      },
      "source": [
        "# Big Dataset (6 month)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcmdcQOzCxTP",
        "outputId": "03abb74d-f3c9-42d6-8990-44b5abc7c539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-27 13:50:54--  https://docs.google.com/uc?export=download&confirm=t&id=1TWD3QDBrsn90zxbDom94BF4fR-NOp0Pi\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.12.14, 2607:f8b0:4025:815::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.12.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9j2cqssojvgudttt0dt7h65n2638c7ms/1701093000000/15669009389864827016/*/1TWD3QDBrsn90zxbDom94BF4fR-NOp0Pi?e=download&uuid=4919f37d-6ee9-4470-bd11-43a0f0ed72ab [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-11-27 13:50:54--  https://doc-0c-1g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9j2cqssojvgudttt0dt7h65n2638c7ms/1701093000000/15669009389864827016/*/1TWD3QDBrsn90zxbDom94BF4fR-NOp0Pi?e=download&uuid=4919f37d-6ee9-4470-bd11-43a0f0ed72ab\n",
            "Resolving doc-0c-1g-docs.googleusercontent.com (doc-0c-1g-docs.googleusercontent.com)... 172.217.12.1, 2607:f8b0:4025:815::2001\n",
            "Connecting to doc-0c-1g-docs.googleusercontent.com (doc-0c-1g-docs.googleusercontent.com)|172.217.12.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 229426987 (219M) [application/x-zip-compressed]\n",
            "Saving to: ‘dataset_telecom.zip’\n",
            "\n",
            "dataset_telecom.zip 100%[===================>] 218.80M  33.5MB/s    in 6.9s    \n",
            "\n",
            "2023-11-27 13:51:01 (31.6 MB/s) - ‘dataset_telecom.zip’ saved [229426987/229426987]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1TWD3QDBrsn90zxbDom94BF4fR-NOp0Pi' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1TWD3QDBrsn90zxbDom94BF4fR-NOp0Pi\" -O dataset_telecom.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip /content/dataset_telecom.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBC8o8bpvegT",
        "outputId": "2e59f7e2-1d03-4fbb-8c7f-4058b3c63df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_6.16~6.30.xlsx\n",
            "data_9.16~9.30.xlsx\n",
            "data_10.1~10.15.xlsx\n",
            "data_7.1~7.15.xlsx\n",
            "data_10.16~10.31.xlsx\n",
            "data_8.1~8.15.xlsx\n",
            "data_6.1~6.15.xlsx\n",
            "data_11.16~11.30.xlsx\n",
            "data_9.1~9.15.xlsx\n",
            "data_7.16~7.31.xlsx\n",
            "data_8.16~8.31.xlsx\n",
            "data_11.1~11.15.xlsx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def update_dic(df_id,file_path_id,columnSorting='start time'):\n",
        "  dic_id=np.load(file_path_id,allow_pickle=True).item()\n",
        "  for key in dic_id:\n",
        "    dic_id[key]=np.append(dic_id[key],df_id[key].to_numpy())\n",
        "  sorted_idx=dic_id[columnSorting].argsort()\n",
        "  for key in dic_id:\n",
        "    dic_id[key]=dic_id[key][sorted_idx]\n",
        "  return dic_id\n",
        "\n",
        "def update_dic(df_id,dataset_dic,id):\n",
        "  dic_id=dataset_dic[id]\n",
        "  for key in dic_id:\n",
        "    dic_id[key]=np.append(dic_id[key],df_id[key].to_numpy())\n",
        "  return dic_id\n",
        "\n",
        "def sort_dic_id(dic_id,columnSorting='start time'):\n",
        "  sorted_idx=dic_id[columnSorting].argsort()\n",
        "  for key in dic_id:\n",
        "    dic_id[key]=dic_id[key][sorted_idx]\n",
        "  return dic_id\n",
        "\n",
        "def create_dic(df_id,drop_column=['month','date','user id']):\n",
        "  dic_id={}\n",
        "  for name in df_id.columns:\n",
        "    if name not in drop_column :\n",
        "      dic_id[name]=df_id[name].to_numpy()\n",
        "  return dic_id\n",
        "\n",
        "def extract_data_in_dic(file_path,dataset_dic):\n",
        "  df=pd.read_excel(file_path)\n",
        "  os.makedirs('./TelecomDataset',exist_ok=True)\n",
        "  grouped_id=df.groupby('user id')\n",
        "\n",
        "  for id,df_id in grouped_id:\n",
        "\n",
        "    if id in dataset_dic :\n",
        "      dic_id=update_dic(df_id, dataset_dic,id)\n",
        "    else:\n",
        "      dic_id=create_dic(df_id)\n",
        "    dic_id=sort_dic_id(dic_id,columnSorting='start time')\n",
        "    dataset_dic[id]=dic_id\n",
        "  return dataset_dic\n",
        "\n",
        "def extract_data(file_path):\n",
        "  df=pd.read_excel(file_path)\n",
        "  os.makedirs('./TelecomDataset',exist_ok=True)\n",
        "  grouped_id=df.groupby('user id')\n",
        "  for id,df_id in grouped_id:\n",
        "    file_path_id=os.path.join('.','TelecomDataset',id+'.npy')\n",
        "    if os.path.isfile(file_path_id):\n",
        "      dic_id=update_dic(df_id, file_path_id)\n",
        "    else:\n",
        "      dic_id=create_dic(df_id)\n",
        "    np.save(file_path_id,dic_id)\n",
        "\n",
        "dataset_dic={}\n",
        "os.makedirs(\"TelecomDataset\",exist_ok=True)\n",
        "for file in os.listdir(\".\"):\n",
        "\n",
        "    if file.endswith(\".xlsx\"):\n",
        "      print(file)\n",
        "      dataset_dic= extract_data_in_dic(os.path.join(\".\", file),dataset_dic)\n",
        "    np.save(\"./TelecomDataset/dataset_dic.npy\",dataset_dic)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSgaHpq2vLrT"
      },
      "outputs": [],
      "source": [
        "def delete_overlaps_dataset(dataset_dic):\n",
        "  for id in dataset_dic:\n",
        "    dic_id=dataset_dic[id]\n",
        "    dic_id=delete_overlaps_id(dic_id)\n",
        "    dataset_dic[id]=dic_id\n",
        "  return dataset_dic\n",
        "\n",
        "def delete_overlaps_id(dic_id):\n",
        "  for i in range(len(dic_id['start time'])-1):\n",
        "    if dic_id['start time'][i+1]<dic_id['end time'][i]:\n",
        "      dic_id['end time'][i]=dic_id['start time'][i+1]\n",
        "  return dic_id\n",
        "\n",
        "def convervt_id_to_idx(dataset_dic):\n",
        "  dataset_dic_idx={}\n",
        "  list_id=[]\n",
        "  for idx,id in enumerate(dataset_dic):\n",
        "    dataset_dic_idx[idx]=dataset_dic[id]\n",
        "    list_id.append(id)\n",
        "\n",
        "  return dataset_dic_idx, list_id\n",
        "def get_dic_station(dataset_dic):\n",
        "  dic_station={}\n",
        "  list_station=[]\n",
        "  for i in dataset_dic:\n",
        "\n",
        "    latitudes=dataset_dic[i][\"latitude\"]\n",
        "    longitudes=dataset_dic[i][\"longitude\"]\n",
        "    for position in zip(latitudes,longitudes):\n",
        "      if np.isnan(position[0]):\n",
        "        position=(np.float64(-1),position[1])\n",
        "      if np.isnan(position[1]):\n",
        "        position=(position[0],np.float64(-1))\n",
        "      if position in dic_station:\n",
        "        dic_station[position][\"number\"]+=1\n",
        "      else:\n",
        "        dic_station[position]={}\n",
        "        dic_station[position][\"number\"]=1\n",
        "        list_station.append(position)\n",
        "        dic_station[position][\"idx\"]=len(list_station)-1\n",
        "\n",
        "  return dic_station, list_station\n",
        "def add_class(dataset_dic,dic_station):\n",
        "  for idx in dataset_dic:\n",
        "    latitudes=dataset_dic[idx][\"latitude\"]\n",
        "    longitudes=dataset_dic[idx][\"longitude\"]\n",
        "    for position in zip(latitudes,longitudes):\n",
        "      if np.isnan(position[0]):\n",
        "          position=(np.float64(-1),position[1])\n",
        "      if np.isnan(position[1]):\n",
        "          position=(position[0],np.float64(-1))\n",
        "      dataset_dic[idx][\"class\"]=dic_station[position][\"idx\"]\n",
        "  return dataset_dic\n",
        "\n",
        "def get_mean_connect_time(dataset_dic):\n",
        "  total_nb=0\n",
        "  sum=0\n",
        "  for idx in dataset_dic:\n",
        "    start_times=dataset_dic[idx][\"start time\"]\n",
        "    end_times=dataset_dic[idx][\"end time\"]\n",
        "    total_nb+=len(start_times)\n",
        "    sum+=(end_times-start_times).sum().astype('timedelta64[s]')\n",
        "\n",
        "  return sum/total_nb\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}